# SwitchAI âš¡

A **multi-model conversational AI assistant** with an **ExpressJS backend** and a **React + Vite frontend**.  
Switch between **OpenAI** and **Gemini** seamlessly and chat in real time with streaming responses.

---

## ğŸ“‚ Project Structure

```
SwitchAI/
â”œâ”€â”€ backend/                # ExpressJS Backend
â”‚   â”œâ”€â”€ providers/          # AI Provider Integrations
â”‚   â”‚   â”œâ”€â”€ base.py         # Abstract base provider
â”‚   â”‚   â”œâ”€â”€ openai_provider.py
â”‚   â”‚   â””â”€â”€ gemini_provider.py
â”‚   â”œâ”€â”€ server.js           # Main ExpressJS server
â”‚   â”œâ”€â”€ package.json        # Backend dependencies
â”‚   â””â”€â”€ .env.example        # Example environment variables
â”‚
â”œâ”€â”€ frontend/               # React + Vite Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # Sidebar, ChatPanel, ModelSwitcher
â”‚   â”‚   â”œâ”€â”€ hooks/          # Custom hooks (e.g. SSE)
â”‚   â”‚   â”œâ”€â”€ api/            # API calls
â”‚   â”‚   â”œâ”€â”€ App.jsx         # Main app
â”‚   â”‚   â””â”€â”€ main.jsx        # Entry point
â”‚   â”œâ”€â”€ package.json        # Frontend dependencies
â”‚   â””â”€â”€ vite.config.js      # Vite config
â”‚
â”œâ”€â”€ .env.example            # Example API keys
â””â”€â”€ README.md               # Documentation
```

---

## ğŸš€ Features

- ğŸ”„ Switch between **OpenAI** and **Gemini**
- ğŸ’¬ Real-time chat with **Server-Sent Events (SSE)**
- ğŸ¨ Modern **React + Vite frontend**
- âš¡ Lightweight **ExpressJS backend**

---

## ğŸ› ï¸ Setup & Installation

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your-username/switchai.git
cd switchai
```

### 2ï¸âƒ£ Backend Setup (ExpressJS)
```bash
cd backend
npm install
```

Create a `.env` file in `backend/` (see `.env.example`).

Run the backend:
```bash
node server.js
```

### 3ï¸âƒ£ Frontend Setup (React + Vite)
```bash
cd frontend
npm install
npm run dev
```

---

## ğŸ”‘ Environment Variables

Create a `.env` file in `backend/` with:

```
OPENAI_API_KEY=your_openai_key
GEMINI_API_KEY=your_gemini_key
PORT=5000
```

---

## ğŸ§ª Usage

1. Start backend (`node server.js`).
2. Start frontend (`npm run dev`).
3. Open [http://localhost:5173](http://localhost:5173).
4. Select your model (OpenAI or Gemini) and start chatting ğŸš€

---

## ğŸ“œ License

This project is licensed under the **MIT License**.

---

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome!  
Feel free to open an issue or submit a PR.
